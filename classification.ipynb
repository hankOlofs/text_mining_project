{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f9efbf-dc09-45dd-947f-fe06d0d56690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import markovify\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457ae287-74de-4474-92f4-10e00e381589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Anaconda3\\envs\\textmining\\lib\\site-packages\\pandas\\core\\generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "amazon_raw = pd.read_csv('train.csv', header=None)\n",
    "amazon = amazon_raw.iloc[0:100000,:]\n",
    "amazon.columns = ['polarity', 'title', 'text']\n",
    "amazon.polarity.replace({1:0, 2:1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5b0e57-df64-4f2b-97dd-8050e12781b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity    0\n",
       "title       3\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ee25f6-76fa-45b8-b009-bc193a3b6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecom_raw = pd.read_csv('ecom_reviews.csv')\n",
    "ecom = ecom_raw.iloc[:,4:6]\n",
    "ecom.columns = ['text', 'rating']\n",
    "#ecom['polarity'] = ecom.rating.map(lambda x: 0 if x < 3 else 1 if x > 3 else 3)\n",
    "ecom['polarity'] = [0 if x < 3 else 1 if x > 3 else 3 for x in ecom.rating]\n",
    "ecom_unfiltered = ecom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5a111f-bfd0-4dcd-bec5-92b2a194911f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17448\n",
       "0     2370\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom = ecom[ecom['text'].notna()]\n",
    "ecom = ecom.iloc[:, [2,0]]\n",
    "ecom = ecom[ecom.polarity.isin([0,1])]\n",
    "ecom.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7325ae-b077-4d9e-839e-9f97cc2b7149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>I love this dress. i usually get an xs but it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm 5\"5' and 125 lbs. i ordered the s petite t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>This dress is perfection! so pretty and flatte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    polarity                                               text\n",
       "0          1  Absolutely wonderful - silky and sexy and comf...\n",
       "1          1  Love this dress!  it's sooo pretty.  i happene...\n",
       "3          1  I love, love, love this jumpsuit. it's fun, fl...\n",
       "4          1  This shirt is very flattering to all due to th...\n",
       "5          0  I love tracy reese dresses, but this one is no...\n",
       "6          1  I aded this in my basket at hte last mintue to...\n",
       "7          1  I ordered this in carbon for store pick up, an...\n",
       "8          1  I love this dress. i usually get an xs but it ...\n",
       "9          1  I'm 5\"5' and 125 lbs. i ordered the s petite t...\n",
       "11         1  This dress is perfection! so pretty and flatte..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae835fe0-af1b-4a4a-aa56-903ebc45eb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing cv, total=   4.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.90      0.48      2370\n",
      "           1       0.98      0.75      0.85     17448\n",
      "\n",
      "    accuracy                           0.77     19818\n",
      "   macro avg       0.65      0.82      0.66     19818\n",
      "weighted avg       0.90      0.77      0.80     19818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes(training_data = amazon, test_data = ecom):\n",
    "    # Data\n",
    "    X_train = training_data['text']\n",
    "    y_train = training_data['polarity']\n",
    "    X_test = test_data['text']  \n",
    "    \n",
    "    # Pipeline\n",
    "    pipe = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB())], verbose = True)\n",
    "    # Fit training data\n",
    "    pipe.fit(X_train, y_train)\n",
    "        \n",
    "    # Predict labels for test data\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# Print the result\n",
    "y_test = ecom['polarity']\n",
    "print(classification_report(y_test, naive_bayes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a690c80-20f1-4fc6-b353-001eafaf3518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8804117468967605"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17448/ecom.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90430af4-e26f-475a-b1a0-f8f884cb0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing cv, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.76      0.44      2370\n",
      "           1       0.96      0.76      0.85     17448\n",
      "\n",
      "    accuracy                           0.76     19818\n",
      "   macro avg       0.63      0.76      0.64     19818\n",
      "weighted avg       0.88      0.76      0.80     19818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, naive_bayes(amazon[0:1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e09eaee-6e73-4110-b28c-6285ddf7dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amazon_text\n",
    "amazon_rated0 = amazon[amazon.polarity == 0]['text']\n",
    "text_r0 = '\\n'.join([i for i in amazon_rated0.apply(str)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfd614d-7a7c-4d0c-a5cb-de2a8cf79014",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_rated1 = amazon[amazon.polarity == 1]['text']\n",
    "text_r1 = '\\n'.join([i for i in amazon_rated1.apply(str)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb4d82f4-b667-46d5-94d3-851724a788d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markovify.text.NewlineText at 0x2668f3a87c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_r0 = markovify.NewlineText(text_r0)\n",
    "amazon_r0.compile(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc4bba34-b530-459a-9f24-b6d65d9d2157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markovify.text.NewlineText at 0x2668f3a8b80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_r1 = markovify.NewlineText(text_r1)\n",
    "amazon_r1.compile(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f7c5139-8b4a-4b6e-9c2e-427edf017501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(amazon_r0, open('amazon_r0.pkl', 'wb'))\n",
    "# pickle.dump(amazon_r1, open('amazon_r1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13b5a880-6d9f-4f1d-9e2b-35693037db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_r0_synth = [amazon_r0.make_sentence() for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b69b361-deef-428f-8690-6b4d47c0748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_r1_synth = [amazon_r1.make_sentence() for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e69f88b-6856-43cb-8236-ad2a3a713bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_r0_synth_df = pd.DataFrame({'polarity' : itertools.repeat(0, 1000), 'text' : amazon_r0_synth})\n",
    "amazon_r1_synth_df = pd.DataFrame({'polarity' : itertools.repeat(1, 1000), 'text' : amazon_r1_synth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f12b4c-e458-4738-ba6f-226678eb4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_synth = pd.concat([amazon_r0_synth_df, amazon_r1_synth_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f8931fb-4d94-404d-aa2e-09f8af9dace0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_synth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "353d9b86-0e52-419f-b579-3fa0b912535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing cv, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.86      0.44      2370\n",
      "           1       0.97      0.73      0.83     17448\n",
      "\n",
      "    accuracy                           0.74     19818\n",
      "   macro avg       0.64      0.79      0.64     19818\n",
      "weighted avg       0.89      0.74      0.79     19818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = ecom['polarity']\n",
    "print(classification_report(y_test, naive_bayes(training_data = amazon_synth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b85c3a9-12b3-40e4-a83d-10d0b3f9d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# params = {\n",
    "#     'cv__binary' : (False, True),\n",
    "#     'cv__ngram_range' : ((1, 1), (1, 2)),\n",
    "#     'clf__C' : (1, 0.1),\n",
    "#     'clf__gamma' : ('scale', 'auto')\n",
    "# }\n",
    "\n",
    "def classify(classifier, training_data = amazon_synth, test_data = ecom):\n",
    "    # Data\n",
    "    X_train = training_data['text']\n",
    "    y_train = training_data['polarity']\n",
    "    X_test = test_data['text']  \n",
    "    \n",
    "    # Pipeline\n",
    "    pipe = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', classifier)], verbose = True)\n",
    "    # Fit training data\n",
    "    pipe.fit(X_train, y_train)\n",
    "        \n",
    "    # Predict labels for test data\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da359a1d-183a-4db7-a6a6-c0d6243e42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing cv, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.76      0.38      2370\n",
      "           1       0.95      0.69      0.80     17448\n",
      "\n",
      "    accuracy                           0.70     19818\n",
      "   macro avg       0.60      0.72      0.59     19818\n",
      "weighted avg       0.87      0.70      0.75     19818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_synth = svm.SVC()\n",
    "y_pred_svm = classify(svm_synth)\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9946a-2548-4eee-aadb-73a8e9a70dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing cv, total=   2.7s\n"
     ]
    }
   ],
   "source": [
    "svm_org = svm.SVC()\n",
    "y_pred_svm = classify(classifier = svm_org, training_data = amazon[0:50000])\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42aed790-9097-4f46-bebe-3e1b0b8da67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(classifier, params, training_data=amazon_synth, test_data=ecom):\n",
    "    \n",
    "    X_train = training_data['text']\n",
    "    y_train = training_data['polarity']\n",
    "    X_test = test_data['text']  \n",
    "        \n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('cv', CountVectorizer()),\n",
    "            ('clf', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    grid_search = GridSearchCV(pipe, params, cv = 3, verbose = 3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    return grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15996e9a-1ed4-45b1-9797-54c5d0d7b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=True, cv__ngram_range=(1, 1);, score=0.793 total time=  37.9s\n",
      "[CV 2/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=True, cv__ngram_range=(1, 1);, score=0.785 total time=  38.4s\n",
      "[CV 3/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=True, cv__ngram_range=(1, 1);, score=0.791 total time=  41.0s\n",
      "\tclf__activation: 'tanh'\n",
      "\tclf__hidden_layer_sizes: (200, 200)\n",
      "\tclf__learning_rate_init: 0.002\n",
      "\tcv__binary: True\n",
      "\tcv__ngram_range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.79      0.40      2370\n",
      "           1       0.96      0.70      0.81     17448\n",
      "\n",
      "    accuracy                           0.72     19818\n",
      "   macro avg       0.61      0.75      0.61     19818\n",
      "weighted avg       0.88      0.72      0.76     19818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# neural net\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'cv__binary' : (True,),\n",
    "    'cv__ngram_range' : ((1, 1),),\n",
    "    'clf__activation' : ('tanh',),\n",
    "    'clf__hidden_layer_sizes' : ((200, 200),),\n",
    "    'clf__learning_rate_init' : (0.002,)\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(max_iter = 800)\n",
    "y_pred_mlp = classify(mlp, params, training_data = amazon[0:5000])\n",
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ae7e0e8-29a4-426f-88ce-7b3d805c5f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV 1/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=True, cv__ngram_range=(1, 1);, score=0.820 total time=  11.3s\n",
      "[CV 2/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=True, cv__ngram_range=(1, 1);, score=0.786 total time=  11.4s\n",
      "[CV 3/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=True, cv__ngram_range=(1, 1);, score=0.791 total time=  11.0s\n",
      "[CV 1/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=False, cv__ngram_range=(1, 1);, score=0.784 total time=  11.2s\n",
      "[CV 2/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=False, cv__ngram_range=(1, 1);, score=0.814 total time=  13.5s\n",
      "[CV 3/3] END clf__activation=tanh, clf__hidden_layer_sizes=(200, 200), clf__learning_rate_init=0.002, cv__binary=False, cv__ngram_range=(1, 1);, score=0.791 total time=  12.3s\n",
      "\tclf__activation: 'tanh'\n",
      "\tclf__hidden_layer_sizes: (200, 200)\n",
      "\tclf__learning_rate_init: 0.002\n",
      "\tcv__binary: True\n",
      "\tcv__ngram_range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.80      0.46      2370\n",
      "           1       0.97      0.77      0.86     17448\n",
      "\n",
      "    accuracy                           0.77     19818\n",
      "   macro avg       0.64      0.79      0.66     19818\n",
      "weighted avg       0.89      0.77      0.81     19818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'cv__binary' : (True, False,),\n",
    "    'cv__ngram_range' : ((1, 1),),\n",
    "    'clf__activation' : ('tanh',),\n",
    "    'clf__hidden_layer_sizes' : ((200, 200),),\n",
    "    'clf__learning_rate_init' : (0.002,)\n",
    "}\n",
    "\n",
    "mlp_synth = MLPClassifier(max_iter = 500)\n",
    "y_pred_mlp_synth = classify(mlp, params)\n",
    "print(classification_report(y_test, y_pred_mlp_synth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
